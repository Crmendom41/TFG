{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10efdea",
   "metadata": {},
   "source": [
    "# DATABASE CREATION\n",
    "*Cristina Mendoza*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e3516",
   "metadata": {},
   "source": [
    "### Creation of a .csv file combining the downloaded tables from ADAS 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e86ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# folder with all the cases (nhc)\n",
    "input_folder = # only the cases (nhc) must be in the input folder\n",
    "output_folder =  # It must be a different folder from the input. There should be the csv with the IDs and it is were the csv file will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(input_dir, output_dir):\n",
    "    # function to access the csv files of each patient and join them into a single dataframe\n",
    "\n",
    "    # list to save the final dataframe (will all patients)\n",
    "    all_patients_df = []\n",
    "    \n",
    "    for patient in os.listdir(input_dir):  # enter the folder of the nhc of the patient\n",
    "        patient_dir = os.path.join(input_dir, patient).replace(\"\\\\\",\"/\") # windows uses \"/\" (it has to be changed)\n",
    "        \n",
    "        patient_dfs_raw = [] # list to save the dfs (raw)\n",
    "        patient_files = [] # list to save the names of the csv files\n",
    "\n",
    "        # Check if \"PRE\" directory exists\n",
    "        if not any(case.upper().startswith('PRE') for case in os.listdir(patient_dir)):\n",
    "            print(f\"No 'PRE' directory found for patient: {patient}\")\n",
    "            continue\n",
    "\n",
    "        for case in os.listdir(patient_dir): # enter the folder of the study (if it starts with PRE or pre)\n",
    "            # if it starts with PRE or pre\n",
    "            if case.upper().startswith('PRE'):\n",
    "                case_dir = os.path.join(patient_dir, case).replace(\"\\\\\",\"/\")\n",
    "\n",
    "                # Check if \"CSV\" directory exists\n",
    "                if not any(folder.upper().startswith(\"CSV\") for folder in os.listdir(case_dir)):\n",
    "                    print(f\"No 'CSV' directory found for patient: {patient}\")\n",
    "                    continue\n",
    "\n",
    "                # Enter the folder starting with CSV\n",
    "                for folder in os.listdir(case_dir):\n",
    "                    if folder.upper().startswith(\"CSV\"):\n",
    "                        csv_dir = os.path.join(case_dir, folder).replace(\"\\\\\", \"/\")\n",
    "                        \n",
    "                        # list with the names of the csv files of each patient\n",
    "                        csv_files = [file for file in os.listdir(csv_dir) if file.endswith('.csv')]\n",
    "                        patient_files.extend(csv_files)\n",
    "                        \n",
    "                        # list with the dfs of each patient\n",
    "                        csv_df_list = [pd.read_csv(os.path.join(csv_dir, file), delimiter=';') for file in csv_files]\n",
    "                        patient_dfs_raw.extend(csv_df_list)\n",
    "                        \n",
    "        # dictionary with the name of the file and the dataframe of each patient\n",
    "        csv_dict = dict(zip(patient_files, patient_dfs_raw))\n",
    "        \n",
    "        # Exclude the data from \"numerical\" dataframes (not relevant for structural and morphological atrial remodeling)\n",
    "        csv_dict = {k: v for k, v in csv_dict.items() if \"Numerical\" not in k}\n",
    "\n",
    "        # Exclude patients without csv\n",
    "        if not csv_dict:\n",
    "            continue\n",
    "        \n",
    "        # Take the NHC from each patient from the 1st key of its dictionary\n",
    "        patient_number = list(csv_dict.keys())[0].split(\"_\")[0] \n",
    "\n",
    "        #Create an empty dictionary to include the dfs of each patient\n",
    "        final_dict = {}\n",
    "        \n",
    "        # create new variable names\n",
    "        for key, df in csv_dict.items():\n",
    "            chamber_name = key.split(\"_\")[1] # Take the name of the chamber (LA or RA) from the keys\n",
    "            df.set_index(df.columns[0], inplace = True) # Convert the first column into indices (row names)\n",
    "            flattened_df = df.stack() # Flatten the dataframes into a single row\n",
    "\n",
    "            for (row_name, col_name), value in flattened_df.items():\n",
    "                new_var_name = f\"{chamber_name}_{row_name}_{col_name}\" # Create the new variable name\n",
    "                final_dict[new_var_name] = value # Add the new variable to the dictionary\n",
    "        \n",
    "        # Convert the dictionary into a dataframe\n",
    "        patient_df_flat = pd.DataFrame(final_dict, index = [patient_number])\n",
    "        # Substitute the unwanted characters from the variables and convert numerical data into float type data\n",
    "        patient_df_flat.rename(columns = lambda x: x.replace(\" \", \"_\"), inplace = True) # change \" \" by \"_\"\n",
    "        patient_df_flat.rename(columns = lambda x: x.replace(\"__\",\"_\"), inplace = True) # change \"__\" by \"_\"\n",
    "        for col in patient_df_flat.columns:\n",
    "            if patient_df_flat[col].dtype == \"object\":\n",
    "                patient_df_flat[col] = patient_df_flat[col].str.replace(\",\",\".\").astype(float) # change \",\" by \".\" and convert to float\n",
    "        \n",
    "        all_patients_df.append(patient_df_flat)\n",
    "\n",
    "    # Concatenate the rows of all patients vertically\n",
    "    final_df = pd.concat(all_patients_df, axis = 0, ignore_index = False)\n",
    "    final_df['ID']= np.nan\n",
    "\n",
    "    # Make the indices of int type to allow correspondency to the ID dataframe\n",
    "    final_df.index = final_df.index.astype(int)\n",
    "    \n",
    "    # Add the column of the patient's ID (to sort them like the excel clinical database)\n",
    "    id_df = pd.read_csv(os.path.join(output_dir, \"id_csv.csv\").replace(\"\\\\\",\"/\"), delimiter = \";\", header = None)\n",
    "    \n",
    "    id_df.columns = ['NHC', 'ID']\n",
    "\n",
    "    for ind, nhc in enumerate(id_df['NHC']):\n",
    "        if nhc in final_df.index:\n",
    "            final_df['ID'][nhc] = id_df['ID'][ind]\n",
    "\n",
    "    # sort by ID (as in the excel)\n",
    "    final_df.sort_values(by = 'ID', inplace = True)\n",
    "\n",
    "    # Make the ID column become the first column\n",
    "    cols = ['ID'] + [col for col in final_df.columns if col != 'ID'] \n",
    "    final_df = final_df[cols]\n",
    "    final_df['ID'] = final_df['ID'].astype(int) # Convert ID variable to integer\n",
    " \n",
    "      \n",
    "    return final_df              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738037c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the function for the given directories\n",
    "final_df = csv_to_df(input_folder, output_folder)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb4546",
   "metadata": {},
   "source": [
    "### Create new columns\n",
    "\n",
    "- From the structural remodeling data, create new variables corresponding to the body of the atria (by subtracting the values of the structures like valves and veins from the total area). Recalculate the percentages too.\n",
    "\n",
    "- Create new variables for the regions. (this is for future research related to this study)\n",
    "    - Posterior wall: 3a+3b+3c+3d\n",
    "    - Floor: 7a+7b+7c+7d\n",
    "    - Lateral wall: 6\n",
    "    - Anterior wall: 4a+4b+4c+4d\n",
    "    - Septal wall: 8\n",
    "    - Carines: 1a+1b+2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c689d9",
   "metadata": {},
   "source": [
    "**New variables for fibrosis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00265baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicis_list = ['RA_0%', 'LA_0%']\n",
    "finals_list = [\"_Total_Area_(cm2)\",\"_BZ+Core_(cm2)\", \"_BZ_(cm2)\", \"_Core_(cm2)\", \"_Invalid_(cm2)\"]\n",
    "\n",
    "# Create the new variables for \"body\" by subtracting the different structures from the total\n",
    "new_cols_list = []\n",
    "\n",
    "for inici in inicis_list:\n",
    "    for final in finals_list:\n",
    "        variables_resta = [name for name in final_df.columns if name.startswith(inici) and name.endswith(final)]\n",
    "        variables_resta = [element for element in variables_resta if \"layer\" not in element]\n",
    "        variables_resta = [element for element in variables_resta if \"body\" not in element]\n",
    "        nova_col = inici + '_body' + final\n",
    "        new_cols_list.append(nova_col)\n",
    "        final_df[nova_col] = final_df[inici + \"_layer\" + final] - final_df[variables_resta].sum(axis = 1)\n",
    "        \n",
    "        \n",
    "# Create the new variables for \"body\" in %:\n",
    "\n",
    "# list without Total_Area\n",
    "new_cols_list_no_total = [element for element in new_cols_list if \"Total\" not in element]\n",
    "# list of new variables (%):\n",
    "new_cols_perc_list = [element.replace(\"cm2\",\"%\") for element in new_cols_list_no_total]\n",
    "new_cols_perc_list\n",
    "\n",
    "for ind, col in enumerate(new_cols_perc_list):\n",
    "    cambra = col.split(\"_\")[0]\n",
    "    final_df[col] = round(final_df[new_cols_list_no_total[ind]]/final_df[cambra + \"_0%_body_Total_Area_(cm2)\"]*100,2)\n",
    "\n",
    " \n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dea05",
   "metadata": {},
   "source": [
    "**New variables for the LA regions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cb5d2",
   "metadata": {},
   "source": [
    "- Create new variables by grouping the regions (numerical):\n",
    "    - Posterior wall: 3a+3b+3c+3d\n",
    "    - Floor: 7a+7b+7c+7d\n",
    "    - Lateral wall: 6\n",
    "    - Anterior wall: 4a+4b+4c+4d\n",
    "    - Septal wall: 8\n",
    "    - Carines: 1a+1b+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c407ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of new variables\n",
    "\n",
    "new_regions = [\"Carina\", \"PosteriorWall\", \"AneriorWall\", \"LateralWall\", \"Floor\", \"SeptalWall\"]\n",
    "new_regions_num = [[\"1\",\"2\"],[\"3\"],[\"4\"],[\"6\"],[\"7\"],[\"8\"]]\n",
    "finals_list = [\"_Total_Area_(cm2)\",\"_BZ+Core_(cm2)\", \"_BZ_(cm2)\", \"_Core_(cm2)\", \"_Invalid_(cm2)\"]\n",
    "\n",
    "new_cols_list = []\n",
    "\n",
    "for ind, region in enumerate(new_regions):\n",
    "    for final in finals_list:\n",
    "        new_col = \"LA_\" + region + final\n",
    "        new_cols_list.append(new_col)\n",
    "\n",
    "new_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of variables that we want to sum (numerical regions)\n",
    "\n",
    "new_regions = [\"Carina\", \"PosteriorWall\", \"AneriorWall\", \"LateralWall\", \"Floor\", \"SeptalWall\"]\n",
    "new_regions_num = [[\"1\",\"2\"],[\"3\"],[\"4\"],[\"6\"],[\"7\"],[\"8\"]]\n",
    "finals_list = [\"_Total_Area_(cm2)\",\"_BZ+Core_(cm2)\", \"_BZ_(cm2)\", \"_Core_(cm2)\", \"_Invalid_(cm2)\"]\n",
    "\n",
    "dict_old_cols = {}\n",
    "for ind, region in enumerate(new_regions):\n",
    "    region_list = []\n",
    "    for col in final_df.columns:\n",
    "        for val in col.split(\"_\")[1:]:\n",
    "            for i in new_regions_num[ind]:\n",
    "                if val.startswith(i) == True:\n",
    "                    region_list.append(col)\n",
    "    dict_old_cols[region] = region_list\n",
    "\n",
    "dict_old_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4220ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the new variables (keys) and the variables that conform them (values)\n",
    "new_cols_dict = {}\n",
    "for new_col in new_cols_list:\n",
    "    for key in dict_old_cols.keys():\n",
    "        if new_col.split(\"_\")[1] == key:\n",
    "            values = dict_old_cols.get(key)\n",
    "            var_list = []\n",
    "            for var in values:\n",
    "                if new_col.split(\"_\")[2:] == var.split(\"_\")[2:]:\n",
    "                    var_list.append(var)\n",
    "                    new_cols_dict[new_col] = var_list\n",
    "                    \n",
    "new_cols_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df\n",
    "final_df = final_df.assign(**{key:final_df[columns].sum(axis = 1) for key, columns in new_cols_dict.items()})\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d234c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the new variables for the regions in %:\n",
    "\n",
    "# list without \"Total_Area\"\n",
    "new_cols_list_no_total = [element for element in new_cols_list if \"Total\" not in element]\n",
    "# list of new variables (%):\n",
    "new_cols_perc_list = [element.replace(\"cm2\",\"%\") for element in new_cols_list_no_total]\n",
    "new_cols_perc_list\n",
    "\n",
    "for ind, col in enumerate(new_cols_perc_list):\n",
    "    regio = col.split(\"_\")[1]\n",
    "    denom = final_df['LA_' + regio + \"_Total_Area_(cm2)\"]\n",
    "    final_df[col] = np.where(denom != 0, round(final_df[new_cols_list_no_total[ind]] / denom * 100, 2), np.nan)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e34ac6",
   "metadata": {},
   "source": [
    "### Save the ADAS 3D variables into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adas_df = final_df\n",
    "adas_df.to_csv(os.path.join(output_folder, \"final_df_adas.csv\").replace(\"\\\\\",\"/\"), float_format='%.2f', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913a9ff",
   "metadata": {},
   "source": [
    "### Open the Excel's database (clinical data + tricuspid measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec999b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_dir =  #directory where the excel database is stored\n",
    "excel_df = pd.read_csv(excel_dir, delimiter=';')\n",
    "\n",
    "# set the NHC as the indices (like in the adas database)\n",
    "excel_df.set_index('NHC', inplace = True)\n",
    "excel_df.index.name = None\n",
    "excel_df.columns = excel_df.columns.str.replace(\" \",\"_\") # substitute the \" \" in the database by \"_\"\n",
    "excel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219c0ea",
   "metadata": {},
   "source": [
    "Create the new featue corresponding to the eccentricity index of the TA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df[\"Eccentricity_1\"] = excel_df[\"DMIN_PRE_ADASmm\"]/excel_df[\"DMAX_PRE_ADAS_mm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee2bb1",
   "metadata": {},
   "source": [
    "### Concatenate the dataframes to unify the databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ceac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the ID column from the ADAS 3D dataframe because it is already in the Excel database.\n",
    "adas_df = adas_df.drop('ID', axis = 1)\n",
    "\n",
    "# Concatenate the two dataframes to create the final database.\n",
    "bbdd_final = pd.concat([excel_df,adas_df], axis = 1)\n",
    "\n",
    "bbdd_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7b252",
   "metadata": {},
   "source": [
    "Substitute % by \"perc\" because the % simbol disappears in the csv.\n",
    "\n",
    "\n",
    "It will also be change in the variables containing 0% layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdd_final.columns = bbdd_final.columns.str.replace(\"%\",\"perc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a347157",
   "metadata": {},
   "source": [
    "### Save the final database as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fa496",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbdd_final.to_csv(os.path.join(output_folder, \"final_df_all.csv\").replace(\"\\\\\",\"/\"), float_format='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
